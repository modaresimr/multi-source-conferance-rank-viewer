{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:50:07.694294Z",
     "start_time": "2021-10-20T09:50:07.640288Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyquery import PyQuery as pq\n",
    "def getDBLP(URL):\n",
    "    doc=pq(url=URL)\n",
    "    det= doc(\".visit.drop-down\")\n",
    "    data={'site':det('.head a').attr('href')}\n",
    "    \n",
    "    links=det('.body a')\n",
    "    for l in links:\n",
    "        text=pq(l).text()\n",
    "        if(text):\n",
    "            data[text]=l.attrib['href']\n",
    "    if len(links)<3:\n",
    "        all=[doc('#index-side-panel').next().find('a'),\n",
    "        doc('#info-section').next().find('a')]\n",
    "        \n",
    "        for item in all:\n",
    "            if(item):\n",
    "                data[item.text()]=item.attr('href')\n",
    "        \n",
    "        \n",
    "    if not(data['site']): \n",
    "        for p in data:\n",
    "            if(data[p]):\n",
    "                data['site']=data[p]\n",
    "                break\n",
    "    return data\n",
    "import json\n",
    "all=json.load(open('core-jnls.json'))\n",
    "\n",
    "# getDBLP('https://dblp.uni-trier.de/db/conf/ant/index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T10:15:53.254334Z",
     "start_time": "2021-10-20T10:15:52.024959Z"
    }
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "import time\n",
    "for item in all:\n",
    "    i+=1\n",
    "    if(item['DBLP Source'] and not('Links' in item)):\n",
    "#         print(item['Title'])\n",
    "        try:\n",
    "            item['Links']=getDBLP(item['DBLP Source'])\n",
    "            print(f\"{i}\\t{item['Title']}==== {item['Links']['site']}\")\n",
    "        except:\n",
    "            print(f'error {item[\"Title\"]}')\n",
    "        time.sleep(1)\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T10:15:46.425998Z",
     "start_time": "2021-10-20T10:15:46.423530Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T10:15:59.506446Z",
     "start_time": "2021-10-20T10:15:59.480139Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('core-jnls.json', 'w') as fp:\n",
    "    json.dump(all, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T16:59:17.298035Z",
     "start_time": "2021-10-19T16:16:47.659422Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install pyquery\n",
    "from pyquery import PyQuery as pq\n",
    "import json\n",
    "\n",
    "def getCoreData(conf, id):\n",
    "    if(conf):\n",
    "        TYPE = 'Conference'\n",
    "        URL = f'http://portal.core.edu.au/conf-ranks/{id}'\n",
    "    else:\n",
    "        TYPE = 'Journal'\n",
    "        URL = f'http://portal.core.edu.au/jnl-ranks/{id}'\n",
    "    doc=pq(url=URL)\n",
    "    det= doc(\"#detail\")\n",
    "    \n",
    "    \n",
    "    data={\n",
    "    'CoreId':id,\n",
    "    'Type':TYPE,\n",
    "    'Title':det('h2:first').text(),\n",
    "    'Acronym':'',\n",
    "    'Acronym2':'',\n",
    "    'DBLP Source':'',\n",
    "    'Rank':'',\n",
    "    'Rank Source':'',\n",
    "    'Field':[],\n",
    "    'Info':[]    \n",
    "    }\n",
    "\n",
    "    details=det('.detail')\n",
    "    for i in range(len(details)):\n",
    "        rows=details.eq(i)('.row')\n",
    "        row=rows.eq(0)\n",
    "        splt=row.text().split(':')\n",
    "        titr=splt[0].strip()\n",
    "        val=row.text()[len(splt[0])+1:].strip()\n",
    "\n",
    "        if titr=='Acronym':\n",
    "            data[titr]=val\n",
    "        elif titr=='DBLP Source':\n",
    "            if(val!=\"N/A\"):\n",
    "                data[titr]=val\n",
    "                data['Acronym2']=val.split('/')[-1]\n",
    "        elif titr=='Source':\n",
    "            info={'Source':'','Rank':'','Field Of Research':[]}\n",
    "            for j in range(len(rows)):\n",
    "                row=rows.eq(j)\n",
    "                splt=row.text().split(':')\n",
    "                titr=splt[0].strip()\n",
    "                val=row.text()[len(splt[0])+1:].strip()\n",
    "\n",
    "                if titr=='Field Of Research':\n",
    "                    val=val.replace('â€ ','')\n",
    "                    info['Field Of Research'].append(val)                \n",
    "                    if not (val in data['Field']): data['Field'].append(val)\n",
    "                elif val=='':\n",
    "                    info['other']=row.html().strip().replace('\\n','').replace('  ','').replace('a href=\"/core','a href=\"http://portal.core.edu.au/core')\n",
    "                else:\n",
    "                    if(titr=='Rank' and data['Rank']==''): \n",
    "                        data['Rank']=val\n",
    "                        data['Rank Source']=info['Source']\n",
    "                    info[titr]=val\n",
    "            data['Info'].append(info)\n",
    "\n",
    "        \n",
    "        if not(conf):\n",
    "            doc=pq(url=f'http://portal.core.edu.au/jnl-ranks/?search={data[\"Title\"]}&by=all&source=all&sort=atitle&page=1')\n",
    "            det= doc(\"table tr td a\").attr('href')\n",
    "            if not (det == None):\n",
    "                data['DBLP Source']=det\n",
    "                data['Acronym2']=det.split('/')[-1]\n",
    "            \n",
    "           \n",
    "    return data\n",
    "\n",
    "confs=[]\n",
    "for i in range(2302):\n",
    "    print(i,end=' ')\n",
    "    try:\n",
    "        confs.append(getCoreData(conf=True,id=i))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "with open('core-conf2021.json', 'w') as fp:\n",
    "    json.dump(confs, fp)\n",
    "\n",
    "# jnls=[]\n",
    "# for i in range(937):\n",
    "#     print(i,end=' ')\n",
    "#     try:\n",
    "#         jnls.append(getCoreData(conf=False,id=i))\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "    \n",
    "\n",
    "# with open('core-jnls2021.json', 'w') as fp:\n",
    "#     json.dump(jnls, fp)    \n",
    "    \n",
    "# import csv\n",
    "# with open('core2020.tsv', 'wt') as out_file:\n",
    "#     tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "#     tsv_writer.writerow(['name', 'field'])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T17:51:24.178954Z",
     "start_time": "2021-10-20T17:51:18.536370Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_scimagojr(year=2019):\n",
    "    info=json.load(open('scimagojr_info.json'))\n",
    "    print(info['area']['1000'])\n",
    "    url=f'https://www.scimagojr.com/shapeofscience/ajaxmap.php?authorcountry=0&year={year}'\n",
    "    df=pd.read_csv(url,delimiter=';')\n",
    "    data={}\n",
    "    for k,row in df.iterrows():\n",
    "#         cats=row['CATEGORIAS'].split(',')\n",
    "#         areas=row['AREAS'].split(',')\n",
    "        \n",
    "#         obj={\n",
    "#             'Id':row['SOURCEID'],\n",
    "#             'Title':row['SOURCETITLE'],\n",
    "            \n",
    "#             'SJR':row['SJR'],\n",
    "            \n",
    "#         }\n",
    "        forbiden=['posX','posY','Cluster','wDegree','CATEGORIAS','AREAS','SCIELO']\n",
    "        obj={k:row[k] for k in row.keys() if not(k in forbiden)}\n",
    "        obj['Topic']={y:[x for x in row['CATEGORIAS'].split(',') if x[0:2]==y[0:2]] for y in row['AREAS'].split(',')}\n",
    "        \n",
    "        data[row['SOURCEID']]=obj\n",
    "        \n",
    "    with open(f'scimagojr_{year}.json', 'w') as fp:\n",
    "        json.dump(data, fp)\n",
    "    return pd.DataFrame.from_dict(data, orient='index')\n",
    "a=get_scimagojr(2019)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T22:53:00.568305Z",
     "start_time": "2021-10-20T22:52:58.771765Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def get_scimagojr_journal(year=2020):\n",
    "    info=json.load(open('scimagojr_info.json'))\n",
    "    \n",
    "    url=f'https://www.scimagojr.com/journalrank.php?year={year}&type=j&area=1700&out=xls'\n",
    "    df=pd.read_csv(url,delimiter=';')\n",
    "    data=[]\n",
    "    for k,row in df.iterrows():\n",
    "#         cats=row['CATEGORIAS'].split(',')\n",
    "#         areas=row['AREAS'].split(',')\n",
    "        \n",
    "#         obj={\n",
    "#             'Id':row['SOURCEID'],\n",
    "#             'Title':row['SOURCETITLE'],\n",
    "            \n",
    "#             'SJR':row['SJR'],\n",
    "            \n",
    "#         }\n",
    "        forbiden=['posX','posY','Cluster','wDegree','CATEGORIAS','AREAS','SCIELO']\n",
    "        obj={k:row[k] if row[k]==row[k] else '' for k in row.keys() if not(k in forbiden)}\n",
    "#         obj['Topic']={y:[x for x in row['CATEGORIAS'].split(',') if x[0:2]==y[0:2]] for y in row['AREAS'].split(',')}\n",
    "#         print(obj)\n",
    "        data.append(obj)\n",
    "        \n",
    "    with open(f'scimagojr_journal_{year}.json', 'w') as fp:\n",
    "        json.dump(data, fp)\n",
    "    return data;\n",
    "a=get_scimagojr_journal(2020)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T22:39:12.314552Z",
     "start_time": "2021-10-20T22:39:12.311633Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.nan=='a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T08:01:59.676968Z",
     "start_time": "2021-10-22T08:01:59.545158Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def update_citescore_journal():\n",
    "    info=json.load(open('scimagojr_journal_2020.json'))\n",
    "    for d in info:\n",
    "        d['CiteScore']=0\n",
    "        d['SNIF']=0\n",
    "#         d['Percentile']=0\n",
    "    idm={d['Sourceid']:d for d in info}\n",
    "    \n",
    "    url=f'citescore.csv'\n",
    "    df=pd.read_csv(url)\n",
    "    data=[]\n",
    "    for k,row in df.iterrows():\n",
    "#         cats=row['CATEGORIAS'].split(',')\n",
    "#         areas=row['AREAS'].split(',')\n",
    "        id=row['Scopus Source ID']\n",
    "        \n",
    "        if(id in idm):\n",
    "#             print(row)\n",
    "            d=idm[id]\n",
    "            d['CiteScore']=row['CiteScore 2020']\n",
    "            d['SNIP']=row['SNIP']\n",
    "#             d['Percentile']=row['Percentile']\n",
    "        else: \n",
    "#             print(row)\n",
    "            pass\n",
    "            \n",
    "#         obj={\n",
    "#             'Id':row['SOURCEID'],\n",
    "#             'Title':row['SOURCETITLE'],\n",
    "            \n",
    "#             'SJR':row['SJR'],\n",
    "            \n",
    "#         }\n",
    "        \n",
    "    with open(f'scimagojr_journal_2020_cs.json', 'w') as fp:\n",
    "        json.dump(info, fp)\n",
    "    return info;\n",
    "a=update_citescore_journal()\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T12:05:36.672859Z",
     "start_time": "2021-10-22T11:59:03.397284Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyquery import PyQuery as pq\n",
    "\n",
    "def update_link_journal():\n",
    "    info=json.load(open('scimagojr_journal_2020_cs_link.json'))\n",
    "    try:\n",
    "#         for d in info:\n",
    "#             d['Scope']=''\n",
    "        for d in info:\n",
    "            if(d.get('Scope','')!=''):continue\n",
    "            print(f\"{d['Sourceid']}:{d['Title']}\")\n",
    "    #         d['Site']=\n",
    "            \n",
    "            d['Links']={}\n",
    "            d['Scope']=''\n",
    "            doc=pq(url=f'https://www.scimagojr.com/journalsearch.php?q={d[\"Sourceid\"]}&tip=sid&clean=0')\n",
    "            links=doc('#question_journal')\n",
    "            for l in links:\n",
    "                d['Links'][l.text]=l.attrib['href']\n",
    "\n",
    "            x=doc('div.fullwidth')[0]\n",
    "            txt=pq(x).text()\n",
    "            for c in x.getchildren():\n",
    "                txt=txt.replace(pq(c).text(),'')\n",
    "            d['Scope']=txt.strip()\n",
    "    #         d['Site']=d['Links'].get('Homepage','')\n",
    "    #         if not d['Site']:\n",
    "    #             for p in d['Links']:\n",
    "    #                 d['Site']=d['Links'][p]\n",
    "    #                 break\n",
    "\n",
    "    #         print(d)    \n",
    "    #         return\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    with open(f'scimagojr_journal_2020_cs_link.json', 'w') as fp:\n",
    "        json.dump(info, fp)\n",
    "    return info;\n",
    "a=update_link_journal()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T10:50:57.225686Z",
     "start_time": "2021-10-22T10:50:57.026493Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T13:26:32.858283Z",
     "start_time": "2021-10-22T13:26:32.855043Z"
    }
   },
   "outputs": [],
   "source": [
    "int(1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T20:06:20.372297Z",
     "start_time": "2021-10-22T20:05:17.461616Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyquery import PyQuery as pq\n",
    "\n",
    "def update_reviw_time():\n",
    "    info=json.load(open('scimagojr_journal_2020_cs_link.json'))\n",
    "    \n",
    "    for d in info:\n",
    "#             if(d.get('ReviewFirst','')!=''):\n",
    "#                  del d['ReviewFirst']\n",
    "#                  del d['ReviewFinal']\n",
    "#             continue\n",
    "            if ('elsevier' in d['Links'].get('Homepage','')):\n",
    "                print(f\"{d['Sourceid']}:{d['Title']}\")# {d['Links'].get('Homepage','')}\")\n",
    "                for Issn in d['Issn'].split(', '):\n",
    "                    issn2=(f'{Issn[0:4]}-{Issn[4:8]}')\n",
    "                    try:\n",
    "                        d['Review']={}\n",
    "                        doc=pq(f'https://journalinsights.elsevier.com/journals/{issn2}/review_speed')\n",
    "                        for i in range(1,4):\n",
    "                            td=doc(f'section.graph-data.linegraph tbody tr:nth-child({i}) td')\n",
    "                            d['Review'][pq(td[0]).text()]={\n",
    "                                'First':int(float(pq(td[1]).text())*7),\n",
    "                                'Final':int(float(pq(td[2]).text())*7)\n",
    "                            }\n",
    "\n",
    "                    except  Exception as e:\n",
    "                        print(e)\n",
    "                    try:\n",
    "                        d['Acceptance']={}\n",
    "                        doc=pq(f'https://journalinsights.elsevier.com/journals/{issn2}/acceptance_rate')\n",
    "                        for i in range(1,4):\n",
    "                            td=doc(f'section.graph-data.percentage_bars tbody tr:nth-child({i}) td')\n",
    "                            d['Acceptance'][pq(td[0]).text()]={\n",
    "                                'Submission':int(float(pq(td[1]).text())),\n",
    "                                'Accept':int(float(pq(td[2]).text())),\n",
    "                                'Rate':int(float(pq(td[3]).text()))\n",
    "                            }\n",
    "                        print(d)\n",
    "\n",
    "                    except  Exception as e:\n",
    "                        print(e)\n",
    "                        \n",
    "            if ('springer2343243242' in d['Links'].get('Homepage','')):\n",
    "                try:\n",
    "                        d['Review']={}\n",
    "                        doc=pq(d['Links']['Homepage'])\n",
    "                        sel=lambda p:doc(f\"dd.app-journal-metrics__details[data-test='\"+p+\"']\").text()\n",
    "                        td=doc(f\"dd.app-journal-metrics__details[data-test='impact-factor-value']\")\n",
    "#                         year=sel('impact-factor-value').split(' ')[1][1:5]\n",
    "                        year=2020\n",
    "                        IF=sel('impact-factor-value').split(' ')[0]\n",
    "                        IF5=sel('five-year-impact-factor-value').split(' ')[0]\n",
    "                        first=sel('metrics-speed-value').split(' ')[0]\n",
    "                        final=sel('metrics-acceptance-time-value').split(' ')[0]\n",
    "                        \n",
    "                        if(first or final):\n",
    "                            d['Review'][year]={}\n",
    "                        if first: d['Review'][year]['First']=int(first)\n",
    "                        if final: d['Review'][year]['Final']=int(final)\n",
    "                            \n",
    "                        print(f\"{d['Sourceid']}:{d['Title']}\")# {d['Links'].get('Homepage','')}\")\n",
    "                except  Exception as e:\n",
    "                        print(e)\n",
    "                        print(d['Links'].get('Homepage',''))\n",
    "                        \n",
    "    \n",
    "    with open(f'scimagojr_journal_2020_cs_link.json', 'w') as fp:\n",
    "        json.dump(info, fp)\n",
    "    return info;\n",
    "a=update_reviw_time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T11:13:49.372544Z",
     "start_time": "2022-02-26T11:13:49.186018Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def update_aut_rank():\n",
    "    info=json.load(open('scimagojr_journal_2020_cs_link.json'))\n",
    "    aut_q=pd.read_csv('aut-q-2020.csv')\n",
    "    aut_q['Qnum']=5-aut_q['Q'].str.replace('Q','').astype(int)\n",
    "    aut_q_m=aut_q.groupby('ISSN').mean()[['Qnum']]\n",
    "    aut_q_m['Qnum']='Q'+(5-aut_q_m['Qnum'].round().astype(int)).astype(str)\n",
    "    aut_q_m.index=aut_q_m.index.str.replace('-','')\n",
    "    \n",
    "    for d in info:\n",
    "       if d['Issn']:\n",
    "         for issn in d['Issn'].split(', '):\n",
    "            if issn in aut_q_m.index:\n",
    "                d['aut']=aut_q_m.loc[issn]['Qnum']\n",
    "    \n",
    "    with open(f'scimagojr_journal_2020_cs_link_aut.json', 'w') as fp:\n",
    "        json.dump(info, fp)\n",
    "    return info;\n",
    "a=update_aut_rank()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T11:13:54.871580Z",
     "start_time": "2022-02-26T11:13:54.453672Z"
    }
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T14:12:13.986888Z",
     "start_time": "2021-10-22T14:12:13.573646Z"
    }
   },
   "outputs": [],
   "source": [
    "doc=pq(f'https://www.springer.com/journal/466')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T20:01:16.808893Z",
     "start_time": "2021-10-22T20:01:16.596658Z"
    }
   },
   "outputs": [],
   "source": [
    "issn2='0168-874X'\n",
    "d={}\n",
    "d['Acceptance']={}\n",
    "doc=pq(f'https://journalinsights.elsevier.com/journals/{issn2}/acceptance_rate')\n",
    "for i in range(1,4):\n",
    "    td=doc(f'section.graph-data.percentage_bars tbody tr:nth-child({i}) td')\n",
    "    print(td)\n",
    "    d['Acceptance'][pq(td[0]).text()]={\n",
    "        'Submission':int(float(pq(td[1]).text())),\n",
    "        'Accept':int(float(pq(td[2]).text())),\n",
    "        'Rate':int(float(pq(td[3]).text()))\n",
    "    }\n",
    "    \n",
    "d\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
